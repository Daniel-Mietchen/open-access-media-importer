#!/usr/bin/env python
# -*- coding: utf-8 -*-

from os import path
from sys import argv, stderr
from urllib2 import urlparse
from time import sleep

import csv
# csv.field_size_limit must be reset according to
# <http://lethain.com/handling-very-large-csv-and-xml-files-in-python/>
csv.field_size_limit(999999999)

import wikitools

from helpers import template
from model import session, setup_all, create_all, set_source, \
    Article, Journal, SupplementaryMaterial

try:
    action = argv[1]
    target = argv[2]
except IndexError:  # no arguments given
    stderr.write("""
oa-put – Open Access Importer upload operations

usage:  oa-put upload-media [source]

""")
    exit(1)

try:
    assert(action in ['upload-media'])
except AssertionError:  # invalid action
    stderr.write("Unknown action “%s”.\n" % action)
    exit(2)

try:
    exec "from sources import %s as source_module" % target
except ImportError:  # invalid source
    stderr.write("Unknown source “%s”.\n" % target)
    exit(3)

set_source(target)
setup_all(True)

import config

if action == 'upload-media':
    media_refined_directory = config.get_media_refined_source_path(target)
    wiki = wikitools.wiki.Wiki(config.api_url)
    wiki.login(username=config.username, password=config.password)

    def is_uploaded(material):
        params = {
            'action': 'query',
            'list': 'search',
            'srwhat': 'text',
            'srnamespace': '6',  # media files
            'srsearch': '"%s"+"%s"+"%s"' % (
                material.article.title,
                material.label,
                material.caption.split('.')[0]
            )
        }
        request = wikitools.api.APIRequest(wiki, params)
        result = request.query()
        if result[u'query'][u'searchinfo'][u'totalhits'] > 0:
            return True
        return False

    materials = SupplementaryMaterial.query.filter_by(
        converted=True,
        uploaded=False
    ).all()
    for material in materials:
        url_path = urlparse.urlsplit(material.url).path
        filename = url_path.split('/')[-1] + '.ogv'
        media_refined_path = path.join(media_refined_directory, filename)

        if (path.getsize(media_refined_path) == 0):
            material.converted=False
            continue

        if is_uploaded(material):
            material.uploaded=True
            continue

        wiki_file = wikitools.wikifile.File(wiki=wiki, title=filename)
        wiki_file.upload(
            fileobj = open(media_refined_path, 'r'),
            comment = 'Uploaded with the Open Access Media Importer. (test edit) [[Commons:Bots/Requests#Open_Access_Media_Importer_Bot_.28talk.C2.A0.C2.B7_contribs.29|botrequest]]'
        )
        article_doi = material.article.doi
        authors = material.article.contrib_authors
        article_title = material.article.title
        journal_title = material.article.journal.title
        date = material.article.date
        article_url = material.article.url
        license_url = material.article.license_url
        rights_holder = material.article.copyright_holder
        label = material.label
        caption = material.caption
        page = wikitools.Page(wiki, "File:" + filename, followRedir=True)
        page_template = template.page(article_doi, authors, article_title, journal_title, \
            date, article_url, license_url, rights_holder, label, \
            caption)
        page.edit(text=page_template.encode('utf-8'))
        stderr.write("“%s” uploaded to <%s>.\n" % (
            media_refined_path.encode('utf-8'),
            config.api_url.encode('utf-8')
        ))

        material.uploaded = True
        session.commit()
        sleep(10)  # 6 uploads per minute
