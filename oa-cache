#!/usr/bin/env python
# -*- coding: utf-8 -*-

from os import listdir, path
from sys import argv, stderr, stdout

import csv
# csv.field_size_limit must be reset according to
# <http://lethain.com/handling-very-large-csv-and-xml-files-in-python/>
csv.field_size_limit(999999999)

import errno

try:
    action = argv[1]
    target = argv[2]
except IndexError:
    stderr.write("""
oa-cache – Open Access Importer local operations

usage:  oa-cache convert-media [source] |
        oa-cache find-media [source] |
        oa-cache list-articles [source]

""")
    exit(1)

try:
    assert(action in ['convert-media', 'find-media', 'list-articles'])
except AssertionError:  # invalid action
    stderr.write('Unknown action “%s”.\n' % action)
    exit(2)

try:
    exec "from sources import %s as source_module" % target
except ImportError:  # invalid source
    stderr.write("Unknown source “%s”.\n" % target)
    exit(3)

import config

from helpers import tar

if action == 'convert-media':
    for source_name in config.sources.keys():
        config.get_metadata_refined_source_path(source_name)

if action == 'list-articles':
    csv_writer = csv.writer(stdout)
    # categories based on:
    # “Citation Rules with Examples for Journal Articles on the Internet”
    # <http://www.ncbi.nlm.nih.gov/books/NBK7281/#A55596>
    csv_writer.writerow([
        'Authors',
        'Article Title',
        'Article Abstract',  # not part of citation rules, but useful
        'Journal Title',
        'Date of Publication',
        'Available from',
        'License',  # also not part of citation rules
        'Copyright Holder'  # same here
    ])
    source_path = config.get_metadata_raw_source_path(target)
    for result in source_module.list_articles(source_path):
        dataset = [item.encode('utf-8') for item in
            [
                result['article-contrib-authors'],
                result['article-title'],
                result['article-abstract'],
                result['journal-title'],
                result['article-date'],
                result['article-url'],
                result['article-license-url'],
                result['article-copyright-holder']
            ]
            if 'encode' in dir(item)
            # I have no idea why some results have no encode methods
        ]
        try:
            csv_writer.writerow(dataset)
        except IOError, e:
            if e.errno == errno.EPIPE:
                exit(0)  # broken pipe, exit normally
            else:
                raise

if action == 'find-media':
    results_directory = config.get_metadata_refined_source_path(target)

    fail_cache_path = path.join(results_directory, 'fail_cache')
    try:
        with open(fail_cache_path, 'r') as fail_cache:
            reader = csv.reader(fail_cache)
            fail_filenames = [row[0] for row in reader]
    except IOError:  # file does not exist on first run
        fail_filenames = []

    success_cache_path = path.join(results_directory, 'success_cache')
    try:
        with open(success_cache_path, 'r') as success_cache:
            reader = csv.reader(success_cache)
            success_filenames = [row[0] for row in reader]
    except IOError:  # file does not exist on first run
        success_filenames = []

    with open(fail_cache_path, 'a') as fail_cache:
        with open(success_cache_path, 'a') as success_cache:
            csv_writer_fail = csv.writer(fail_cache)
            csv_writer_success = csv.writer(success_cache)
            #csv_writer_success.writerow([
            #    'Name',
            #    'Authors',
            #    'Article Title',
            #    'Article Abstract',
            #    'Journal Title',
            #    'Date of Publication',
            #    'Available from',
            #    'License',
            #    'Copyright Holder',
            #    'Supplementary Material Label',
            #    'Supplementary Material Caption',
            #    'Supplementary Material Mimetype',
            #    'Supplementary Material Mime-Subtype',
            #    'Supplementary Material URL'
            #])
            source_path = config.get_metadata_raw_source_path(target)
            for result in source_module.list_articles(
                source_path,
                supplementary_materials=True,
                skip = fail_filenames + success_filenames
            ):
                materials = result['supplementary-materials']
                if materials:
                    for material in materials:
                        dataset = [item.encode('utf-8') for item in
                            [
                                result['name'],
                                result['article-contrib-authors'],
                                result['article-title'],
                                result['article-abstract'],
                                result['journal-title'],
                                result['article-date'],
                                result['article-url'],
                                result['article-license-url'],
                                result['article-copyright-holder'],
                                material['label'],
                                material['caption'],
                                material['mimetype'],
                                material['mime-subtype'],
                                material['url']
                            ]
                            if 'encode' in dir(item)
                            # I have no idea why some results have no encode methods
                        ]
                        csv_writer_success.writerow(dataset)
                    else:
                        csv_writer_fail.writerow([result['name']])
    
